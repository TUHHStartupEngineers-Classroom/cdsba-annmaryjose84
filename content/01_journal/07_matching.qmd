---
title: "Matching and Subclassification"
author: "Annmary Jose"
---

# Assignment

1.  Load the data set and necessary pakacges

    ```{r}
    library(tidyverse)
    library(dplyr)
    library(ggdag)
    library(dagitty)
    library(rddensity)

    df <- readRDS("../../Causal_Data_Science_Data/membership.rds")
    view(df)

    ```

2.  Check the relationships between the variables and draw a DAG as you understand the relations.

    ```{r}

    # Correlation matrix
    cor(df[, c("age","sex", "pre_avg_purch", "card","avg_purch")])

    # Define DAG
    dag <- 'dag {
      bb="0,0,1,1"
      "age" [exposure,pos="0.2,0.4"]
      "sex" [pos="0.35,0.5"]
      "pre_avg_purch" [outcome,pos="0.5,0.2"]
      "card" [pos="0.4,0.8"]
      "avg_purch" [pos="0.3,0.8"]
      age -> pre_avg_purch
      age -> card
      age -> avg_purch
      age -> sex
      pre_avg_purch -> "sex"
      avg_purch -> "card"
      card -> pre_avg_purch
      card -> sex
    }'

    # DAG with adjustment sets (and custom layout)
    ggdag_adjustment_set(dag, shadow = T, text = F) +
      guides(color = "none") +  # Turn off legend
      geom_dag_text(color = NA) +
      geom_dag_edges(edge_color = "white") +
      geom_dag_label_repel(aes(label = name))
    ```

    2.  Compute a naive estimate of the average treatment effect.

        ```{r}
        model_naive <- lm(avg_purch ~ card, data = df)
        summary(model_naive)
        ```

Use the following matching methods to obtain more precise estimates:

1.  (Coarsened) Exact Matching.

    ```{r}

    # Load 'MatchIt' library
    library(MatchIt)

    # Without specifying coarsening
    # (1) Matching
    cem <- matchit(card ~ age + pre_avg_purch,
                   data = df, 
                   method = 'cem', 
                   estimand = 'ATE')
    summary(cem)
    # Use matched data
    df_cem <- match.data(cem)

    # (2) Estimation
    model_cem <- lm(avg_purch ~ card, data = df_cem, weights = weights)
    summary(model_cem)
    ```

2.  Nearest-Neighbor Matching.

    ```{r}
    # (1) Matching
    # replace: one-to-one or one-to-many matching
    nn <- matchit(card ~ age + pre_avg_purch,
                  data = df,
                  method = "nearest", # changed
                  distance = "mahalanobis", # changed
                  replace = T)

    # Covariate Balance
    summary(nn)

    # Use matched data
    df_nn <- match.data(nn)

    # (2) Estimation
    model_nn <- lm(avg_purch ~ card, data = df_nn, weights = weights)
    summary(model_nn)
    ```

3.  Inverse Probability Weighting

```{r}
# (1) Propensity scores
model_prop <- glm(card ~ age + pre_avg_purch,
                  data = df,
                  family = binomial(link = "logit"))
summary(model_prop)

# Add propensities to table
df_aug <- df %>% mutate(propensity = predict(model_prop, type = "response"))

# Extend data by IPW scores
df_ipw <- df_aug %>% mutate(
  ipw = (card/propensity) + ((1-card) / (1-propensity)))

# Look at data with IPW scores
df_ipw %>% 
  select(card,age, pre_avg_purch, propensity, ipw)

# (2) Estimation
model_ipw <- lm(avg_purch ~ card,
                data = df_ipw, 
                weights = ipw)
summary(model_ipw)

# Plot histogram of estimated propensities
ggplot(df_aug, aes(x = propensity)) +
  geom_histogram(alpha = .8, color = "white")

# Looking for observations with highest weights
df_ipw %>% 
  select(card,age, pre_avg_purch,, propensity, ipw) %>% 
  arrange(desc(ipw))

# Run with high weights excluded
model_ipw_trim <- lm(card ~ age + pre_avg_purch,
                data = df_ipw %>% filter(propensity %>% between(0.1, 0.5)),
                weights = ipw)
summary(model_ipw_trim)


# Summary of naive and matching methods
modelsummary::modelsummary(list("Naive" = model_naive,
                                "CEM1"  = model_cem,
                                "NN"    = model_nn,
                                "IPW1"  = model_ipw,
                                "IPW2"  = model_ipw_trim))
```
